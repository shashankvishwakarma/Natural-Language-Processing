{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"Mr. Smith made a deal on a beach of Switzerland near WHO.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenizing words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mr.', 'Smith', 'made', 'a', 'deal', 'on', 'a', 'beach', 'of', 'Switzerland', 'near', 'WHO', '.']\n"
     ]
    }
   ],
   "source": [
    "tokenized_words = word_tokenize(sentence)\n",
    "print(tokenized_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PoS tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Mr.', 'NNP'), ('Smith', 'NNP'), ('made', 'VBD'), ('a', 'DT'), ('deal', 'NN'), ('on', 'IN'), ('a', 'DT'), ('beach', 'NN'), ('of', 'IN'), ('Switzerland', 'NNP'), ('near', 'IN'), ('WHO', 'NNP'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "for w in tokenized_words:\n",
    "    tagged_words = nltk.pos_tag(tokenized_words)\n",
    "\n",
    "print(tagged_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (PERSON Mr./NNP)\n",
      "  (PERSON Smith/NNP)\n",
      "  made/VBD\n",
      "  a/DT\n",
      "  deal/NN\n",
      "  on/IN\n",
      "  a/DT\n",
      "  beach/NN\n",
      "  of/IN\n",
      "  (GPE Switzerland/NNP)\n",
      "  near/IN\n",
      "  (ORGANIZATION WHO/NNP)\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "N_E_R = nltk.ne_chunk(tagged_words,binary=False)\n",
    "print(N_E_R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'Most of the outlay will be at home. No surprise there, either. ' \\\n",
    "            'While Samsung has expanded overseas, South Korea is still host to most of its factories and research engineers.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenizing words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Most', 'of', 'the', 'outlay', 'will', 'be', 'at', 'home', '.', 'No', 'surprise', 'there', ',', 'either', '.', 'While', 'Samsung', 'has', 'expanded', 'overseas', ',', 'South', 'Korea', 'is', 'still', 'host', 'to', 'most', 'of', 'its', 'factories', 'and', 'research', 'engineers', '.']\n"
     ]
    }
   ],
   "source": [
    "tokenized_words = word_tokenize(sentence)\n",
    "print(tokenized_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PoS tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Most', 'JJS'), ('of', 'IN'), ('the', 'DT'), ('outlay', 'NN'), ('will', 'MD'), ('be', 'VB'), ('at', 'IN'), ('home', 'NN'), ('.', '.'), ('No', 'DT'), ('surprise', 'NN'), ('there', 'RB'), (',', ','), ('either', 'DT'), ('.', '.'), ('While', 'IN'), ('Samsung', 'NNP'), ('has', 'VBZ'), ('expanded', 'VBN'), ('overseas', 'RB'), (',', ','), ('South', 'NNP'), ('Korea', 'NNP'), ('is', 'VBZ'), ('still', 'RB'), ('host', 'VBN'), ('to', 'TO'), ('most', 'JJS'), ('of', 'IN'), ('its', 'PRP$'), ('factories', 'NNS'), ('and', 'CC'), ('research', 'NN'), ('engineers', 'NNS'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "for w in tokenized_words:\n",
    "    tagged_words = nltk.pos_tag(tokenized_words)\n",
    "\n",
    "print(tagged_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  Most/JJS\n",
      "  of/IN\n",
      "  the/DT\n",
      "  outlay/NN\n",
      "  will/MD\n",
      "  be/VB\n",
      "  at/IN\n",
      "  home/NN\n",
      "  ./.\n",
      "  No/DT\n",
      "  surprise/NN\n",
      "  there/RB\n",
      "  ,/,\n",
      "  either/DT\n",
      "  ./.\n",
      "  While/IN\n",
      "  (PERSON Samsung/NNP)\n",
      "  has/VBZ\n",
      "  expanded/VBN\n",
      "  overseas/RB\n",
      "  ,/,\n",
      "  (GPE South/NNP Korea/NNP)\n",
      "  is/VBZ\n",
      "  still/RB\n",
      "  host/VBN\n",
      "  to/TO\n",
      "  most/JJS\n",
      "  of/IN\n",
      "  its/PRP$\n",
      "  factories/NNS\n",
      "  and/CC\n",
      "  research/NN\n",
      "  engineers/NNS\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "N_E_R = nltk.ne_chunk(tagged_words,binary=False)\n",
    "print(N_E_R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'Great Piano Academy is situated' \\\n",
    "            ' in Mayfair or the City of London and has' \\\n",
    "            ' world-class piano instructors.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenizing words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Great', 'Piano', 'Academy', 'is', 'situated', 'in', 'Mayfair', 'or', 'the', 'City', 'of', 'London', 'and', 'has', 'world-class', 'piano', 'instructors', '.']\n"
     ]
    }
   ],
   "source": [
    "tokenized_words = word_tokenize(sentence)\n",
    "print(tokenized_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PoS tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Great', 'NNP'), ('Piano', 'NNP'), ('Academy', 'NNP'), ('is', 'VBZ'), ('situated', 'VBN'), ('in', 'IN'), ('Mayfair', 'NNP'), ('or', 'CC'), ('the', 'DT'), ('City', 'NNP'), ('of', 'IN'), ('London', 'NNP'), ('and', 'CC'), ('has', 'VBZ'), ('world-class', 'NN'), ('piano', 'NN'), ('instructors', 'NNS'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "for w in tokenized_words:\n",
    "    tagged_words = nltk.pos_tag(tokenized_words)\n",
    "\n",
    "print(tagged_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (GPE Great/NNP)\n",
      "  (PERSON Piano/NNP Academy/NNP)\n",
      "  is/VBZ\n",
      "  situated/VBN\n",
      "  in/IN\n",
      "  (GPE Mayfair/NNP)\n",
      "  or/CC\n",
      "  the/DT\n",
      "  (ORGANIZATION City/NNP)\n",
      "  of/IN\n",
      "  (GPE London/NNP)\n",
      "  and/CC\n",
      "  has/VBZ\n",
      "  world-class/NN\n",
      "  piano/NN\n",
      "  instructors/NNS\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "N_E_R = nltk.ne_chunk(tagged_words,binary=False)\n",
    "print(N_E_R)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
